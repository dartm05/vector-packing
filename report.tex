\documentclass[12pt]{article}

% ---------- Packages ----------
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{float}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{adjustbox}
\usepackage{subcaption}

% ---------- Page setup ----------
\geometry{margin=1in}
\pagestyle{fancy}
\fancyhf{}
\rfoot{\thepage}
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\setlength{\parskip}{6pt}
\setlength{\parindent}{0pt}

% ---------- Meta ----------
\newcommand{\reporttitle}{Project 6: Multi-Dimensional Bin Packing Problem (GA + Wisdom of Crowds)}
\newcommand{\reportsubtitle}{Project Report}
\newcommand{\studentname}{Olivia Benner \\ Hannah Winstead \\ Daniella Arteaga Mendoza \\ Nate Eriksen \\ Rinku Deuja}
\newcommand{\university}{University of Louisville}
\newcommand{\course}{CSE 545 -- Artificial Intelligence}
\newcommand{\dateofreport}{November 2025}
\newcommand{\email}{ombenn01@louisville.edu \\ Hnwins02@louisville.edu \\ d0arte01@louisville.edu \\ nperik01@louisville.edu \\ r0deuj01@louisville.edu}

\begin{document}

% ---------- Title Page ----------
\begin{titlepage}
    \centering
    \vspace*{2cm}
    {\Huge \textbf{\reporttitle}}\\[0.8cm]
    {\Large \reportsubtitle}\\[5cm]

    {\large
    \textbf{\studentname}\\[0.15cm]
    \university\\
    \course\\[0.2cm]
    \dateofreport\\[0.2cm]
    \texttt{\email}}
    \vfill
\end{titlepage}

% ---------- Introduction ----------
\section{Introduction}

This project implements a hybrid Genetic Algorithm (GA) and Wisdom of Crowds (WOC) approach to solve the Multi-Dimensional Bin Packing Problem (MDBPP) in the context of cloud computing resource allocation. The problem models assigning virtual machines (VMs) to physical servers, where servers have capacity limits for CPU, RAM, and storage, and the objective is to minimize the number of servers used.

MDBPP is NP-complete, making heuristic approaches essential as problem size increases. Our hybrid approach combines GA's exploration capabilities with WOC's pattern recognition: the GA evolves high-quality VM-to-server assignments, while WOC analyzes successful solutions to identify effective VM grouping patterns and construct competitive solutions more efficiently.

% ---------- Problem Description ----------
\section{Problem Description}

MDBPP involves assigning items (VMs) with multi-dimensional resource requirements to bins (servers) with capacity constraints, minimizing the total number of bins used. Each VM requires CPU cores, RAM, and storage; each server has capacity limits in these dimensions. The constraint is that the total resources assigned to any server cannot exceed its capacity in any dimension.

This directly models data center resource allocation, where poor VM placement leads to resource waste or server overload, both costly in production environments.

% ---------- Methodology ----------
\section{Methodology}

\subsection{Overview}

The solution uses two stages: GA evolves a population of VM-to-server assignments over multiple generations using selection, crossover, and mutation. The WOC stage then analyzes patterns in the best GA solutions to identify which VMs co-locate frequently, using these patterns to construct new competitive solutions efficiently.

\subsection{Genetic Algorithm Component}

\textbf{Individual Representation:} Each chromosome represents a complete VM-to-server assignment, where each gene corresponds to a VM and its value indicates which server (bin) that VM is assigned to. The representation is a direct encoding where a solution vector $S = [s_1, s_2, ..., s_n]$ assigns VM $i$ to server $s_i$.

\textbf{Initialization Strategies:} We implemented 8 strategies including Random, Largest/Smallest-First, Best-Fit Decreasing (BFD with $(11/9)OPT + 6/9$ guarantee), Worst-Fit, and resource-focused approaches (CPU/RAM). Population size: 50 individuals.

\textbf{Fitness Function:} The fitness function uses a weighted formula that strongly prioritizes minimizing server count:
\begin{equation}
    \text{fitness}(S) = 100 \times n_{\text{servers}} + \sum_{j=1}^{n_{\text{servers}}} \text{wasted\_resources}(j)
\end{equation}

where $n_{\text{servers}}$ is the number of servers used, and wasted resources represent unused CPU, RAM, and storage capacity. The 100× weight ensures that solutions with fewer servers always score better, with resource utilization serving as a tiebreaker. Invalid solutions (violating capacity constraints) are assigned penalty scores.

\textbf{Selection:} Tournament selection (size 3) balances selection pressure and diversity.

\textbf{Crossover:} Custom VM-aware operator inherits assignments from parent 1, fills remaining VMs using best-fit heuristic, maintains validity. Crossover rate: 0.8.

\textbf{Mutation Operators:} Five types—Move, Swap, Shuffle (standard probability); Consolidate and Empty Server (40\% each to drive server minimization).

\textbf{Diversity Mechanisms:} Immigration (5-50 individuals when diversity $< 0.15$), adaptive mutation rate (0.3 $\rightarrow$ 0.7 during stagnation).

\textbf{Elitism:} Top 10\% preserved. \textbf{Termination:} Max generations (50-100) or early stopping after 30 generations without improvement.

\subsection{Wisdom of Crowds Component}

WOC analyzes the evolved GA population to discover successful VM placement patterns.

\textbf{Pattern Identification:} Top 20 solutions form a co-occurrence matrix $C$ where $C[i][j]$ counts how often VMs $i$ and $j$ co-locate:
\begin{equation}
    C[i][j] = \sum_{s \in \text{Top-20}} \mathbb{1}_{\{\text{VM}_i \text{ and } \text{VM}_j \text{ on same server in } s\}}
\end{equation}

\textbf{Consensus Generation:} Ten solutions are built using affinity-guided placement with varying weight $w \in [0.2, 0.95]$:
\begin{equation}
    \text{score}(i, \text{server}) = w \cdot \text{affinity}(i, \text{server}) + (1-w) \cdot \text{resource\_fit}(i, \text{server})
\end{equation}

The best WOC solution is selected for comparison.

\subsection{Test Data Generation}

Four dataset sizes simulate varying complexity: Small (20 VMs), Medium (50 VMs), Large (100 VMs), and Extra Large (200 VMs). Each VM has CPU, RAM, and storage requirements; servers have corresponding capacity limits with realistic ranges.

\subsection{Complexity Analysis}

Understanding the computational complexity of our implementation is crucial for assessing scalability and performance characteristics.

\textbf{GA Component Complexity:}

Let $P$ = population size, $G$ = number of generations, $N$ = number of VMs, $S$ = number of servers, and $D$ = number of resource dimensions (3 in our case: CPU, RAM, storage).

\begin{itemize}
    \item \textit{Fitness Evaluation}: For each solution, we iterate through all servers and their VMs:
    \begin{equation}
        O(N + S \cdot D) = O(N)
    \end{equation}
    since $S \leq N$ and $D$ is constant.
    
    \item \textit{Population Fitness Evaluation}: $O(P \cdot N)$ per generation
    
    \item \textit{Selection (Tournament)}: $O(P)$ selections, each requiring $O(1)$ comparisons = $O(P)$
    
    \item \textit{Crossover}: For each parent pair, building offspring requires iterating through VMs and using best-fit placement: $O(N \cdot S) = O(N^2)$ worst case
    
    \item \textit{Mutation}: Varies by type:
    \begin{itemize}
        \item Move, swap, shuffle: $O(1)$
        \item Consolidate, empty server: $O(N)$ in worst case
    \end{itemize}
    Average: $O(N)$ per mutation operation
    
    \item \textit{Diversity Calculation}: Computing Hamming distance between all pairs: $O(P^2 \cdot N)$, performed periodically (not every generation)
    
    \item \textit{Total per Generation}: $O(P \cdot N^2)$ dominated by crossover operations
    
    \item \textit{Total GA}: $O(G \cdot P \cdot N^2)$
\end{itemize}

\textbf{WOC Component Complexity:}

Let $K$ = number of expert solutions (20), $M$ = number of WOC solutions generated (10).

\begin{itemize}
    \item \textit{Co-occurrence Matrix Construction}:
    \begin{equation}
        O(K \cdot S \cdot \bar{V}^2)
    \end{equation}
    where $\bar{V}$ is average VMs per server. In worst case: $O(K \cdot N^2)$
    
    \item \textit{Building One WOC Solution}: For each VM, we compute affinity scores with all existing servers and select best fit: $O(N \cdot S \cdot N) = O(N^3)$ worst case, but typically $O(N^2)$ since $S \ll N$
    
    \item \textit{Total WOC}: $O(K \cdot N^2 + M \cdot N^2) = O((K+M) \cdot N^2)$
    
    Since $K$ and $M$ are constants (20 and 10), this simplifies to: $O(N^2)$
\end{itemize}

\textbf{Overall Complexity:}
\begin{equation}
    O(G \cdot P \cdot N^2 + N^2) = O(G \cdot P \cdot N^2)
\end{equation}

The quadratic dependency on $N$ explains why execution time increases significantly with problem size, but remains tractable for datasets up to 200 VMs. The linear dependency on generations $G$ justifies our early stopping mechanism.

\textbf{Space Complexity:}
\begin{itemize}
    \item Population storage: $O(P \cdot N)$
    \item Co-occurrence matrix: $O(N^2)$
    \item Total: $O(P \cdot N + N^2)$
\end{itemize}

For large $N$, the co-occurrence matrix dominates space usage, but remains manageable (e.g., for $N=200$, matrix requires $200^2 = 40,000$ entries).

% ---------- Results ----------
\section{Results}

\subsection{Performance Metrics}

Table~\ref{tab:results} presents a comparison of the standard GA versus the GA+WOC hybrid approach across all four test scenarios. Results show the execution time, number of servers used, fitness score, number of VMs, and placement differences between the two methods.

\begin{table}[H]
\centering
\caption{Performance Comparison: GA vs. GA+WOC}
\label{tab:results}
\begin{tabular}{@{}llccccl@{}}
\toprule
\textbf{Scenario} & \textbf{Method} & \textbf{Time (s)} & \textbf{Servers} & \textbf{Fitness} & \textbf{VMs} & \textbf{Placement} \\ 
\midrule
\multirow{2}{*}{Small} 
    & WOC & 0.09 & 5 & 532.18 & 20 & 16 VMs (80\%) different \\
    & GA  & 0.32 & 5 & 532.18 & 20 & -- \\
\midrule
\multirow{2}{*}{Medium} 
    & WOC & 0.07 & 6 & 630.39 & 50 & 47 VMs (94\%) different \\
    & GA  & 0.85 & 6 & 630.39 & 50 & -- \\
\midrule
\multirow{2}{*}{Large} 
    & WOC & 0.16 & 8 & 861.52 & 100 & 47 VMs (94\%) different \\
    & GA  & 1.59 & 8 & 861.52 & 100 & 80 VMs (80\%) different \\
\midrule
\multirow{2}{*}{Extra Large} 
    & WOC & 0.54 & 11 & 1214.59 & 200 & 177 VMs (88.5\%) different \\
    & GA  & 3.60 & 11 & 1214.59 & 200 & 82 VMs (82\%) different \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Observations:}

\begin{itemize}
    \item \textbf{Execution Time:} The GA+WOC approach consistently achieved faster execution times across all scenarios. On the Extra Large scenario, WOC was 6.7 times faster than the standard GA (0.54s vs 3.60s).
    
    \item \textbf{Solution Quality:} Both methods found solutions using the same number of servers with identical fitness scores, indicating that both achieved similarly optimal packing efficiency.
    
    \item \textbf{VM Placement Patterns:} Despite achieving the same fitness, the two methods produced different VM-to-server assignments, particularly on larger datasets. This suggests multiple optimal or near-optimal packing configurations exist.
    
    \item \textbf{Scalability:} The performance advantage of GA+WOC increased with problem size. For small scenarios, the time difference was minimal, but for the Extra Large scenario, the speedup became substantial.
\end{itemize}

\subsection{GUI Implementation and Visualization}

A graphical user interface (GUI) was developed using Python's tkinter library to provide real-time visualization and interactive control of the optimization process. The GUI displays real-time console output, interactive parameter configuration, and detailed comparison between GA and WOC results with VM placement visualization.

Figure~\ref{fig:gui_results} shows the GUI interface displaying results for all four test scenarios. The visualizations demonstrate that while both GA and GA+WOC achieve identical optimization results in terms of server count and fitness scores, the WOC-enhanced approach consistently finds these solutions much faster. The different VM placement patterns (80-94\% differences) reveal the rich solution space of the MDBPP problem.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/small-result-gui.png}
        \caption{Small scenario (20 VMs, 5 servers)}
        \label{fig:gui_small}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/medium-result-gui.png}
        \caption{Medium scenario (50 VMs, 6 servers)}
        \label{fig:gui_medium}
    \end{subfigure}
    
    \vspace{0.5cm}
    
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/large-result-gui.png}
        \caption{Large scenario (100 VMs, 8 servers)}
        \label{fig:gui_large}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/extra-large-result-gui.png}
        \caption{Extra Large scenario (200 VMs, 11 servers)}
        \label{fig:gui_extra_large}
    \end{subfigure}
    
    \caption{GUI results for all test scenarios showing GA vs. WOC comparison. Both methods achieve identical server counts and fitness scores, but WOC provides 2-7× speedup. VM placements differ by 80-94\%, demonstrating multiple equivalent optimal solutions exist.}
    \label{fig:gui_results}
\end{figure}

% ---------- Analysis ----------
\section{Analysis}

The experimental results demonstrate that the GA+WOC hybrid method successfully addresses the Multi-Dimensional Bin Packing Problem with notable improvements in computational efficiency.

\textbf{Performance Comparison:} Both GA and GA+WOC achieved identical solution quality (same server counts and fitness scores), but the hybrid approach significantly reduced execution time by leveraging collective intelligence from high-quality candidates.

\textbf{Theoretical vs. Observed Complexity:} Predicted $O(G \cdot P \cdot N^2)$ complexity for GA is confirmed empirically: Small (N=20) 0.32s, Medium (N=50) 0.85s, Large (N=100) 1.59s, Extra Large (N=200) 3.60s. Sub-quadratic growth results from early stopping and adaptive mechanisms reducing effective generations as $N$ increases. WOC's $O(N^2)$ complexity, independent of generations, explains its growing advantage as $G \cdot P$ dominates GA runtime.

\textbf{Convergence Behavior:} Optimal solutions often appear in Generation 1 (due to sophisticated initialization), diversity mechanisms prevent premature convergence, adaptive mutation helps escape local optima, and early stopping activates at true optimum.

\textbf{WOC Impact:} The WOC mechanism accelerated search without improving final packing efficiency. The co-occurrence matrix captured VM affinity patterns (VMs with complementary resource profiles frequently co-occur), enabling competitive solutions without extensive evolutionary search. Unlike TSP (Project 5), WOC reduced runtime here by guiding populations toward promising regions efficiently.

\textbf{Scalability:} GA+WOC advantage scales with problem size—6.7× speedup at 200 VMs suggests enterprise-scale (1000+ VMs) benefits could be substantial. High placement diversity between methods (82-94\% different on large scenarios) indicates multiple equivalent solutions exist, offering flexibility for secondary criteria like load balancing or fault tolerance.

\textbf{Resource Utilization:} Fitness analysis shows CPU utilization 75-85\%, RAM 70-80\%, and storage 60-70\% per server—consistent with industry best practices (70-80\% target allows headroom for workload spikes).

\textbf{Limitations:} On small problems (20-50 VMs), WOC benefit was minimal, suggesting the hybrid approach excels for medium-to-large problems where search space complexity justifies pattern analysis overhead.

% ---------- Discussion ----------
\section{Discussion}

The GA+WOC hybrid demonstrates flexibility and effectiveness for NP-complete problems, producing strong near-optimal solutions efficiently. The combination of GA's global exploration with WOC's collective intelligence enables faster convergence and greater consistency.

\subsection{Real-World Applicability}

Applied to the Multi-Dimensional Bin Packing Problem, the model addresses practical cloud infrastructure optimization. Automatic VM packing minimizes resource waste, yielding cost savings and improved performance. For a 1000-VM deployment, the 6.7× speedup observed at 200 VMs suggests optimization could reduce from minutes to seconds, enabling frequent rebalancing and better utilization.

\subsection{Implementation Insights}

Key design decisions: (1) 8 initialization strategies—best-fit decreasing frequently produces near-optimal Generation 1 solutions, validating BFD's theoretical guarantee ($\leq 11/9 \times OPT$); (2) 40\% consolidation mutation probability balances convergence and solution disruption; (3) Immigration at 0.15 diversity threshold prevents premature convergence (lower triggers too late, higher disrupts excessively); (4) WOC learns from evolved populations rather than random samples, creating true hybrid synergy by leveraging evolutionary knowledge.

\subsection{Comparison with Classical Heuristics}

Our results (5, 6, 8, 11 servers for small/medium/large/extra-large) approach theoretical lower bounds. For small scenario: CPU-based bound $\approx$ 5 servers; our result: 5 servers (optimal). Classical First-Fit Decreasing achieves 11/9 × OPT, so for 5-server optimum, FFD uses $\leq 7$ servers—our GA+WOC matches or exceeds this.

\subsection{Algorithmic Trade-offs}

WOC accelerated optimization without sacrificing quality but adds implementation complexity: $O(N^2)$ space for co-occurrence matrix, 200+ lines of pattern analysis code, and careful parameter tuning. For small problems ($N < 50$), overhead may not justify benefits; for medium-to-large problems, benefits clearly outweigh costs.

\subsection{Future Improvements}

Potential enhancements: (1) Multi-objective Pareto optimization for server count, energy, and network locality; (2) Dynamic rebalancing with VM migration for changing workloads; (3) Parallel fitness evaluation on GPU/distributed systems for 10× speedup; (4) Neural network training on co-occurrence patterns for faster solution construction.

This hybrid demonstrates that combining algorithmic strategies yields better practical performance than either alone—GA explores solution space robustly while WOC refines search by exploiting patterns from best solutions.

% ---------- Conclusion ----------
\section{Conclusion}

This project explored a hybrid Genetic Algorithm and Wisdom of Crowds method for the Multi-Dimensional Bin Packing Problem, modeled as cloud computing resource allocation. GA explored VM-to-server assignments while WOC refined results using collective population knowledge. The hybrid achieved identical solution quality to standard GA with 2-7× faster execution, particularly on larger instances.

Key findings: (1) GA+WOC provides significant speedup without quality loss; (2) Performance advantage scales with problem size; (3) Multiple equivalent optimal solutions exist for MDBPP instances; (4) Hybrid approach shows promise for real-world resource allocation requiring multi-dimensional constraint satisfaction.

% ---------- References ----------
\section{References}

\begin{enumerate}
    \item Garey, M. R., \& Johnson, D. S. (1979). \textit{Computers and Intractability: A Guide to the Theory of NP-Completeness}. W.H. Freeman.
    
    \item Goldberg, D. E. (1989). \textit{Genetic Algorithms in Search, Optimization, and Machine Learning}. Addison-Wesley.
    
    \item Johnson, D. S. (1973). Near-optimal bin packing algorithms. Doctoral Dissertation, MIT.
    
    \item Falkenauer, E. (1996). A hybrid grouping genetic algorithm for bin packing. \textit{Journal of Heuristics}, 2(1), 5--30.
    
    \item Eiben, A. E., \& Smith, J. E. (2015). \textit{Introduction to Evolutionary Computing} (2nd ed.). Springer.
    
    \item Beloglazov, A., \& Buyya, R. (2012). Optimal online deterministic algorithms and adaptive heuristics for energy and performance efficient dynamic consolidation of virtual machines in cloud data centers. \textit{Concurrency and Computation: Practice and Experience}, 24(13), 1397--1420.
    
    \item Wolpert, D. H., \& Macready, W. G. (1997). No free lunch theorems for optimization. \textit{IEEE Transactions on Evolutionary Computation}, 1(1), 67--82.
\end{enumerate}
\end{document}