# Results Directory

This directory stores all benchmark results and experimental data generated by the project scripts.

## Structure

```
results/
├── benchmarks/          # Benchmark results from algorithm runs
│   ├── production_benchmark_results.json       # Production scenario benchmarks (500-1000 VMs)
│   ├── synthetic_benchmark_results.json        # Synthetic data benchmarks
│   ├── combined_benchmark_results.json         # Combined synthetic + Azure results
│   └── updated_benchmark_results.json          # Updated benchmark results
│
└── convergence/         # GA convergence tracking data
    └── convergence_data.json                   # Generation-by-generation convergence data
```

## File Descriptions

### Benchmarks

**production_benchmark_results.json**
- Generated by: `scripts/benchmarks/benchmark_production_scenarios.py`
- Contains: Benchmarks for production scenarios with 500, 750, and 1000 VMs
- Used by: `presentation/scripts/visualize_production_scenarios.py`
- Format: Array of scenario objects with GA and WoC results

**synthetic_benchmark_results.json**
- Generated by: `presentation/scripts/generate_azure_comparison.py`
- Contains: Benchmarks using synthetic test data (small, medium, large, extra_large)
- Used by: Multiple visualization scripts
- Format: Array of scenario objects with algorithm performance metrics

**combined_benchmark_results.json**
- Generated by: `presentation/scripts/generate_azure_comparison.py`
- Contains: Side-by-side comparison of synthetic vs Azure data results
- Used by: Comparison visualizations
- Format: Dictionary with 'synthetic' and 'azure' keys plus metadata

**updated_benchmark_results.json**
- Generated by: Various benchmark update scripts
- Contains: Latest benchmark results for standard test scenarios
- Used by: `presentation/scripts/update_visualizations.py`
- Format: Array of scenario results

### Convergence Data

**convergence_data.json**
- Generated by: `scripts/benchmarks/capture_convergence_data.py` or `capture_convergence_simple.py`
- Contains: Generation-by-generation fitness tracking for GA convergence analysis
- Used by: `presentation/scripts/update_convergence_visual.py`
- Format: Dictionary keyed by scenario name with convergence arrays

## Regenerating Results

### Production Benchmarks
```bash
python scripts/benchmarks/benchmark_production_scenarios.py
# Output: results/benchmarks/production_benchmark_results.json
```

### Synthetic vs Azure Comparison
```bash
python presentation/scripts/generate_azure_comparison.py
# Output: results/benchmarks/synthetic_benchmark_results.json
#         presentation/data/azure_benchmark_results.json
#         results/benchmarks/combined_benchmark_results.json
```

### Convergence Data
```bash
python scripts/benchmarks/capture_convergence_simple.py
# Output: results/convergence/convergence_data.json
```

## Notes

- All result files are in JSON format for easy parsing and visualization
- Result files are gitignored to avoid storing large data files in the repository
- Always run benchmark scripts from the project root directory
- Timestamps and metadata are included in result files for reproducibility
